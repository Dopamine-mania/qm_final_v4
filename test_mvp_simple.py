#!/usr/bin/env python3
"""
ç®€åŒ–MVPæµ‹è¯•è„šæœ¬
éªŒè¯qm_final4æ ¸å¿ƒåŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from core.emotion_mapper import detect_emotion_enhanced
from core.feature_extractor import AudioFeatureExtractor  
from core.retrieval_engine import VideoRetrievalEngine
from core.video_processor import VideoProcessor

def main():
    print("ğŸš€ qm_final4 MVPç³»ç»ŸéªŒè¯")
    print("=" * 50)
    
    # 1. æµ‹è¯•æƒ…ç»ªè¯†åˆ«
    print("ğŸ§  æµ‹è¯•æƒ…ç»ªè¯†åˆ«...")
    test_input = "æˆ‘ä»Šå¤©å¾ˆç„¦è™‘ï¼Œå·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œæ™šä¸Šç¡ä¸ç€"
    emotion, confidence = detect_emotion_enhanced(test_input)
    print(f"   è¾“å…¥: {test_input}")
    print(f"   âœ… æƒ…ç»ª: {emotion} (ç½®ä¿¡åº¦: {confidence:.3f})")
    
    # 2. æµ‹è¯•ç‰¹å¾æå–
    print("\nğŸµ æµ‹è¯•ç‰¹å¾æå–...")
    extractor = AudioFeatureExtractor()
    test_video = "materials/segments/5min/32_seg000_5min.mp4"
    
    if os.path.exists(test_video):
        features = extractor.extract_video_features(test_video)
        if features:
            print(f"   âœ… ç‰¹å¾æå–æˆåŠŸ")
            print(f"   æ¨¡å‹: {features.get('model_type', 'unknown')}")
            print(f"   ç»´åº¦: {features['feature_vector'].shape}")
        else:
            print("   âŒ ç‰¹å¾æå–å¤±è´¥")
    else:
        print(f"   âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {test_video}")
    
    # 3. æµ‹è¯•æ£€ç´¢å¼•æ“
    print("\nğŸ” æµ‹è¯•æ£€ç´¢å¼•æ“...")
    engine = VideoRetrievalEngine()
    print(f"   ç‰¹å¾æ•°æ®åº“: {len(engine.features_database)} ä¸ªè§†é¢‘")
    
    if engine.features_database:
        results = engine.retrieve_videos(emotion, top_k=3)
        print(f"   âœ… æ£€ç´¢æˆåŠŸ: {len(results)} ä¸ªåŒ¹é…")
        for i, (path, score, info) in enumerate(results, 1):
            video_name = os.path.basename(path)
            print(f"     {i}. {video_name} (ç›¸ä¼¼åº¦: {score:.3f})")
    else:
        print("   âŒ ç‰¹å¾æ•°æ®åº“ä¸ºç©º")
    
    # 4. æµ‹è¯•è§†é¢‘å¤„ç†
    print("\nğŸ¬ æµ‹è¯•è§†é¢‘å¤„ç†...")
    processor = VideoProcessor()
    videos = processor.scan_source_videos()
    print(f"   âœ… å‘ç°æºè§†é¢‘: {len(videos)} ä¸ª")
    
    segments_dir = Path("materials/segments")
    if segments_dir.exists():
        total_segments = len(list(segments_dir.rglob("*.mp4")))
        print(f"   âœ… è§†é¢‘ç‰‡æ®µ: {total_segments} ä¸ª")
    else:
        print("   âŒ ç‰‡æ®µç›®å½•ä¸å­˜åœ¨")
    
    # 5. ç³»ç»ŸçŠ¶æ€æ€»ç»“
    print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€æ€»ç»“")
    print("=" * 50)
    
    if engine.features_database and len(engine.features_database) > 0:
        print("ğŸŸ¢ MVPç³»ç»Ÿå°±ç»ªï¼")
        print(f"   âœ… æƒ…ç»ªè¯†åˆ«: 27ç»´ç»†ç²’åº¦")
        print(f"   âœ… ç‰¹å¾æå–: CLAMP3é™çº§åˆ°Librosa")
        print(f"   âœ… è§†é¢‘æ£€ç´¢: {len(engine.features_database)}ä¸ªç´ æå¯ç”¨")
        print(f"   âœ… å¤„ç†æµç¨‹: ç«¯åˆ°ç«¯éªŒè¯é€šè¿‡")
        
        # ç¤ºä¾‹å®Œæ•´æµç¨‹
        print(f"\nğŸ¯ å®Œæ•´ç–—æ„ˆæµç¨‹ç¤ºä¾‹:")
        print(f"   ç”¨æˆ·è¾“å…¥: \"{test_input}\"")
        print(f"   â†’ è¯†åˆ«æƒ…ç»ª: {emotion} ({confidence:.1%}ç½®ä¿¡åº¦)")
        
        if results:
            selected_video = results[0][0]
            similarity = results[0][1]
            print(f"   â†’ åŒ¹é…è§†é¢‘: {os.path.basename(selected_video)}")
            print(f"   â†’ ç›¸ä¼¼åº¦: {similarity:.1%}")
            print(f"   â†’ è¾“å‡º: ç–—æ„ˆè§†é¢‘æ’­æ”¾")
    else:
        print("ğŸŸ¡ ç³»ç»Ÿéƒ¨åˆ†å°±ç»ª")
        print("   å»ºè®®è¿è¡Œ: python build_priority_material_library.py")
    
    print("\nğŸ‰ MVPéªŒè¯å®Œæˆï¼")

if __name__ == "__main__":
    main()