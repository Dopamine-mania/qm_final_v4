#!/usr/bin/env python3
"""
4.0ç‰ˆæœ¬MVPæµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒç»„ä»¶çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from core.emotion_mapper import detect_emotion_enhanced, get_emotion_music_features
from core.video_processor import VideoProcessor
from core.feature_extractor import AudioFeatureExtractor
from core.retrieval_engine import VideoRetrievalEngine, TherapyVideoSelector

def test_emotion_recognition():
    """æµ‹è¯•æƒ…ç»ªè¯†åˆ«"""
    print("ğŸ§  æµ‹è¯•æƒ…ç»ªè¯†åˆ«æ¨¡å—...")
    
    test_cases = [
        "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡",
        "å¤ªç´¯äº†ï¼Œèº«ä½“å’Œç²¾ç¥éƒ½å¾ˆç–²æƒ«", 
        "ä»Šæ™šåˆå¼€å§‹èƒ¡æ€ä¹±æƒ³ï¼Œåœä¸ä¸‹æ¥",
        "å‹åŠ›å¾ˆå¤§ï¼Œæ„Ÿè§‰å–˜ä¸è¿‡æ°”",
        "æ¯”è¾ƒå¹³é™ï¼Œä½†å¸Œæœ›æ›´æ·±å±‚çš„æ”¾æ¾"
    ]
    
    for i, text in enumerate(test_cases, 1):
        emotion, confidence = detect_emotion_enhanced(text)
        features = get_emotion_music_features(emotion)
        
        print(f"{i}. è¾“å…¥: {text}")
        print(f"   æƒ…ç»ª: {emotion} (ç½®ä¿¡åº¦: {confidence:.1%})")
        print(f"   åŒ¹é…é˜¶æ®µ: {features['åŒ¹é…é˜¶æ®µ']['mood']}")
        print()
    
    print("âœ… æƒ…ç»ªè¯†åˆ«æµ‹è¯•å®Œæˆ\\n")

def test_video_processor():
    """æµ‹è¯•è§†é¢‘å¤„ç†å™¨"""
    print("ğŸ¬ æµ‹è¯•è§†é¢‘å¤„ç†æ¨¡å—...")
    
    processor = VideoProcessor()
    
    # æ£€æŸ¥ffmpeg
    if not processor.check_ffmpeg_availability():
        print("âŒ ffmpegä¸å¯ç”¨ï¼Œè·³è¿‡è§†é¢‘å¤„ç†æµ‹è¯•")
        return False
    
    # æ‰«æè§†é¢‘
    videos = processor.scan_source_videos()
    print(f"å‘ç°è§†é¢‘æ–‡ä»¶: {len(videos)} ä¸ª")
    
    for video in videos:
        print(f"  - {video['file_name']}: {video['duration_formatted']}")
    
    if not videos:
        print("âš ï¸ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ï¼Œè¯·ç¡®ä¿è§†é¢‘ä½äº materials/video/ ç›®å½•ä¸‹")
        return False
    
    print("âœ… è§†é¢‘å¤„ç†æµ‹è¯•å®Œæˆ\\n")
    return True

def test_feature_extractor():
    """æµ‹è¯•ç‰¹å¾æå–å™¨"""
    print("ğŸµ æµ‹è¯•ç‰¹å¾æå–æ¨¡å—...")
    
    extractor = AudioFeatureExtractor()
    
    # æŸ¥æ‰¾æµ‹è¯•è§†é¢‘
    test_video = None
    video_dir = Path("materials/video")
    
    if video_dir.exists():
        for video_file in video_dir.glob("*.mp4"):
            test_video = str(video_file)
            break
    
    if not test_video or not os.path.exists(test_video):
        print("âš ï¸ æœªæ‰¾åˆ°æµ‹è¯•è§†é¢‘æ–‡ä»¶ï¼Œè·³è¿‡ç‰¹å¾æå–æµ‹è¯•")
        return False
    
    print(f"æµ‹è¯•è§†é¢‘: {Path(test_video).name}")
    
    # æå–ç‰¹å¾
    features = extractor.extract_video_features(test_video, extract_ratio=0.25)
    
    if features:
        print("âœ… ç‰¹å¾æå–æˆåŠŸ")
        print(f"   æ—¶é•¿: {features.get('duration', 0):.1f}ç§’")
        print(f"   RMSèƒ½é‡: {features.get('rms_energy', 0):.4f}")
        print(f"   é¢‘è°±è´¨å¿ƒ: {features.get('spectral_centroid', 0):.1f}Hz")
        print(f"   ä¼°è®¡èŠ‚æ‹: {features.get('tempo_estimate', 0):.1f}BPM")
        print(f"   äº®åº¦: {features.get('brightness', 0):.3f}")
        print(f"   æ¸©æš–åº¦: {features.get('warmth', 0):.3f}")
    else:
        print("âŒ ç‰¹å¾æå–å¤±è´¥")
        return False
    
    print("âœ… ç‰¹å¾æå–æµ‹è¯•å®Œæˆ\\n")
    return True

def test_retrieval_engine():
    """æµ‹è¯•æ£€ç´¢å¼•æ“"""
    print("ğŸ” æµ‹è¯•æ£€ç´¢å¼•æ“æ¨¡å—...")
    
    engine = VideoRetrievalEngine()
    
    print(f"ç‰¹å¾æ•°æ®åº“: {len(engine.features_database)} ä¸ªè§†é¢‘")
    print(f"æƒ…ç»ªæ•°æ®åº“: {len(engine.emotion_database)} ç§æƒ…ç»ª")
    
    if len(engine.features_database) == 0:
        print("âš ï¸ ç‰¹å¾æ•°æ®åº“ä¸ºç©ºï¼Œéœ€è¦å…ˆè¿è¡Œç‰¹å¾æå–")
        return False
    
    # æµ‹è¯•æ£€ç´¢
    test_emotion = "ç„¦è™‘"
    results = engine.retrieve_videos(test_emotion, top_k=3)
    
    print(f"\\næ£€ç´¢æµ‹è¯• - æƒ…ç»ª: {test_emotion}")
    if results:
        for i, (path, score, _) in enumerate(results, 1):
            print(f"  {i}. {Path(path).name}: {score:.3f}")
        print("âœ… æ£€ç´¢æµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ æ£€ç´¢æµ‹è¯•å¤±è´¥")
        return False
    
    print("âœ… æ£€ç´¢å¼•æ“æµ‹è¯•å®Œæˆ\\n")
    return True

def test_therapy_selector():
    """æµ‹è¯•ç–—æ„ˆé€‰æ‹©å™¨"""
    print("ğŸŒ™ æµ‹è¯•ç–—æ„ˆé€‰æ‹©å™¨...")
    
    engine = VideoRetrievalEngine()
    selector = TherapyVideoSelector(engine)
    
    test_inputs = [
        "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿ",
        "å¤ªç´¯äº†ï¼Œèº«ä½“å’Œç²¾ç¥éƒ½å¾ˆç–²æƒ«"
    ]
    
    success_count = 0
    
    for user_input in test_inputs:
        result = selector.select_therapy_video(user_input)
        
        if result:
            print(f"è¾“å…¥: {user_input}")
            print(f"æ¨è: {result['video_name']}")
            print(f"æƒ…ç»ª: {result['detected_emotion']} | ç›¸ä¼¼åº¦: {result['similarity_score']:.3f}")
            print()
            success_count += 1
        else:
            print(f"âŒ é€‰æ‹©å¤±è´¥: {user_input}")
    
    if success_count > 0:
        print(f"âœ… ç–—æ„ˆé€‰æ‹©å™¨æµ‹è¯•å®Œæˆ ({success_count}/{len(test_inputs)} æˆåŠŸ)\\n")
        return True
    else:
        print("âŒ ç–—æ„ˆé€‰æ‹©å™¨æµ‹è¯•å¤±è´¥\\n")
        return False

def run_full_test():
    """è¿è¡Œå®Œæ•´æµ‹è¯•"""
    print("=" * 60)
    print("ğŸš€ éŸ³ä¹ç–—æ„ˆAIç³»ç»Ÿ 4.0ç‰ˆæœ¬ - MVPæµ‹è¯•")
    print("=" * 60)
    print()
    
    test_results = []
    
    # 1. æƒ…ç»ªè¯†åˆ«æµ‹è¯•
    try:
        test_emotion_recognition()
        test_results.append(("æƒ…ç»ªè¯†åˆ«", True))
    except Exception as e:
        print(f"âŒ æƒ…ç»ªè¯†åˆ«æµ‹è¯•å¤±è´¥: {e}\\n")
        test_results.append(("æƒ…ç»ªè¯†åˆ«", False))
    
    # 2. è§†é¢‘å¤„ç†æµ‹è¯•
    try:
        video_ok = test_video_processor()
        test_results.append(("è§†é¢‘å¤„ç†", video_ok))
    except Exception as e:
        print(f"âŒ è§†é¢‘å¤„ç†æµ‹è¯•å¤±è´¥: {e}\\n")
        test_results.append(("è§†é¢‘å¤„ç†", False))
    
    # 3. ç‰¹å¾æå–æµ‹è¯•
    try:
        feature_ok = test_feature_extractor()
        test_results.append(("ç‰¹å¾æå–", feature_ok))
    except Exception as e:
        print(f"âŒ ç‰¹å¾æå–æµ‹è¯•å¤±è´¥: {e}\\n")
        test_results.append(("ç‰¹å¾æå–", False))
    
    # 4. æ£€ç´¢å¼•æ“æµ‹è¯•
    try:
        retrieval_ok = test_retrieval_engine()
        test_results.append(("æ£€ç´¢å¼•æ“", retrieval_ok))
    except Exception as e:
        print(f"âŒ æ£€ç´¢å¼•æ“æµ‹è¯•å¤±è´¥: {e}\\n")
        test_results.append(("æ£€ç´¢å¼•æ“", False))
    
    # 5. ç–—æ„ˆé€‰æ‹©å™¨æµ‹è¯•
    try:
        selector_ok = test_therapy_selector()
        test_results.append(("ç–—æ„ˆé€‰æ‹©å™¨", selector_ok))
    except Exception as e:
        print(f"âŒ ç–—æ„ˆé€‰æ‹©å™¨æµ‹è¯•å¤±è´¥: {e}\\n")
        test_results.append(("ç–—æ„ˆé€‰æ‹©å™¨", False))
    
    # æµ‹è¯•æ€»ç»“
    print("=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)
    
    success_count = 0
    for test_name, success in test_results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{test_name:15} {status}")
        if success:
            success_count += 1
    
    print(f"\\næ€»ä½“ç»“æœ: {success_count}/{len(test_results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if success_count == len(test_results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MVPå·²å°±ç»ªï¼")
        return True
    elif success_count >= 3:
        print("âš ï¸ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼ŒMVPåŸºæœ¬å¯ç”¨")
        return True
    else:
        print("âŒ å¤šä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤é—®é¢˜")
        return False

if __name__ == "__main__":
    success = run_full_test()
    
    if success:
        print("\\nğŸš€ å¯åŠ¨å»ºè®®:")
        print("1. è¿è¡Œ: python gradio_retrieval_4.0.py")
        print("2. è®¿é—®Webç•Œé¢")
        print("3. ç‚¹å‡»'åˆå§‹åŒ–ç³»ç»Ÿ'")
        print("4. å¼€å§‹ä½“éªŒæ™ºèƒ½ç–—æ„ˆè§†é¢‘æ¨èï¼")
    else:
        print("\\nğŸ”§ ä¿®å¤å»ºè®®:")
        print("1. ç¡®ä¿ffmpegå·²å®‰è£…")
        print("2. ç¡®ä¿è§†é¢‘æ–‡ä»¶ä½äº materials/video/ ç›®å½•")
        print("3. å®‰è£…æ‰€éœ€ä¾èµ–: pip install -r requirements.txt")
        print("4. æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜")
    
    sys.exit(0 if success else 1)