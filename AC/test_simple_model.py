#!/usr/bin/env python3
"""
æµ‹è¯•ç®€åŒ–ç‰ˆè®­ç»ƒå®Œæˆçš„æƒ…æ„Ÿæ¨¡å‹
"""

import torch
import numpy as np
import json
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleEmotionModel(torch.nn.Module):
    """ç®€åŒ–çš„æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹ - ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´"""
    
    def __init__(self, vocab_size=50000, embed_dim=256, hidden_dim=512, num_emotions=27, dropout=0.3):
        super().__init__()
        self.embedding = torch.nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.lstm = torch.nn.LSTM(embed_dim, hidden_dim, num_layers=2, batch_first=True, 
                                 dropout=dropout, bidirectional=True)
        self.dropout = torch.nn.Dropout(dropout)
        self.classifier = torch.nn.Linear(hidden_dim * 2, num_emotions)
        
    def forward(self, input_ids, attention_mask=None):
        embedded = self.embedding(input_ids)
        lstm_out, (hidden, cell) = self.lstm(embedded)
        
        if attention_mask is not None:
            lengths = attention_mask.sum(dim=1).long() - 1
            batch_size = lstm_out.size(0)
            last_outputs = lstm_out[range(batch_size), lengths]
        else:
            last_outputs = lstm_out[:, -1, :]
        
        output = self.dropout(last_outputs)
        logits = self.classifier(output)
        return logits

class SimpleEmotionInference:
    """ç®€åŒ–ç‰ˆæƒ…æ„Ÿæ¨ç†ç±»"""
    
    def __init__(self, model_path="./models/simple_emotion_model"):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_path = Path(model_path)
        
        # åŠ è½½æ¨¡å‹å’Œé…ç½®
        self._load_model()
        
    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {self.model_path}")
        
        # åŠ è½½æ¨¡å‹æƒé‡å’Œé…ç½®
        checkpoint = torch.load(self.model_path / "model.pth", map_location=self.device)
        
        self.model_config = checkpoint['model_config']
        self.emotion_columns = checkpoint['emotion_columns']
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = SimpleEmotionModel(**self.model_config)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # åŠ è½½è¯æ±‡è¡¨
        with open(self.model_path / "vocab.json", 'r', encoding='utf-8') as f:
            self.vocab_dict = json.load(f)
        
        logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        logger.info(f"   è¯æ±‡è¡¨å¤§å°: {len(self.vocab_dict)}")
        logger.info(f"   æƒ…ç»ªç»´åº¦: {len(self.emotion_columns)}")
        logger.info(f"   è®­ç»ƒF1åˆ†æ•°: {checkpoint.get('f1_score', 'N/A'):.4f}")
        
    def _text_to_ids(self, text, max_length=128):
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºIDåºåˆ—"""
        words = str(text).split()[:max_length]
        ids = [self.vocab_dict.get(word, 1) for word in words]  # 1æ˜¯<UNK>
        
        # å¡«å……åˆ°å›ºå®šé•¿åº¦
        if len(ids) < max_length:
            attention_mask = [1] * len(ids) + [0] * (max_length - len(ids))
            ids.extend([0] * (max_length - len(ids)))  # 0æ˜¯<PAD>
        else:
            attention_mask = [1] * max_length
            
        return ids, attention_mask
    
    def predict_emotion_vector(self, text):
        """é¢„æµ‹æ–‡æœ¬çš„27ç»´æƒ…ç»ªå‘é‡"""
        # é¢„å¤„ç†æ–‡æœ¬
        input_ids, attention_mask = self._text_to_ids(text)
        
        # è½¬æ¢ä¸ºtensor
        input_ids = torch.tensor([input_ids], dtype=torch.long).to(self.device)
        attention_mask = torch.tensor([attention_mask], dtype=torch.long).to(self.device)
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            outputs = self.model(input_ids, attention_mask)
            probabilities = torch.sigmoid(outputs).cpu().numpy()[0]
        
        return probabilities
    
    def analyze_emotion(self, text):
        """åˆ†ææ–‡æœ¬æƒ…ç»ªå¹¶è¿”å›è¯¦ç»†ç»“æœ"""
        vector = self.predict_emotion_vector(text)
        
        # åˆ†æç»“æœ
        emotion_dict = dict(zip(self.emotion_columns, vector))
        
        # æ’åºæ‰¾å‡ºæœ€å¼ºçš„æƒ…ç»ª
        sorted_emotions = sorted(emotion_dict.items(), key=lambda x: x[1], reverse=True)
        
        return {
            'text': text,
            'emotion_vector': vector,
            'emotion_dict': emotion_dict,
            'top_emotions': sorted_emotions[:5],
            'max_emotion': sorted_emotions[0][0],
            'max_intensity': sorted_emotions[0][1],
            'total_intensity': float(np.sum(vector)),
            'active_emotions': int(np.sum(vector > 0.1))
        }

def test_trained_model():
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–ç‰ˆè®­ç»ƒå®Œæˆçš„æƒ…æ„Ÿæ¨¡å‹...")
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
        model_path = Path("./models/simple_emotion_model")
        if not model_path.exists():
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python start_training.py")
            return False
        
        # åˆå§‹åŒ–æ¨ç†å™¨
        inference = SimpleEmotionInference()
        
        # æµ‹è¯•ç”¨ä¾‹
        test_texts = [
            "æˆ‘ä»Šå¤©éå¸¸å¼€å¿ƒï¼Œå¤©æ°”å¾ˆå¥½ï¼",
            "è¿™é¦–æ­Œè®©æˆ‘å¾ˆæ„ŸåŠ¨ï¼Œæƒ³èµ·äº†ç«¥å¹´æ—¶å…‰ã€‚", 
            "æˆ‘å¯¹è¿™ä»¶äº‹æ„Ÿåˆ°å¾ˆæ„¤æ€’å’Œå¤±æœ›ã€‚",
            "çœ‹åˆ°è¿™ä¸ªæ¶ˆæ¯æˆ‘å¾ˆéœ‡æƒŠï¼Œç®€ç›´ä¸æ•¢ç›¸ä¿¡ã€‚",
            "ä»–çš„è¡¨ç°è®©æˆ‘æ„Ÿåˆ°éå¸¸é’¦ä½©ã€‚",
            "è¿™ä¸ªæ•…äº‹å¤ªæœ‰è¶£äº†ï¼Œè®©æˆ‘æ§è…¹å¤§ç¬‘ã€‚",
            "æˆ‘ä¸ºè‡ªå·±çš„è¡Œä¸ºæ„Ÿåˆ°ç¾è€»å’Œå†…ç–šã€‚"
        ]
        
        print("\nğŸ“Š æƒ…æ„Ÿåˆ†ææµ‹è¯•ç»“æœ:")
        print("=" * 80)
        
        for i, text in enumerate(test_texts, 1):
            print(f"\nğŸ” æµ‹è¯• {i}: {text}")
            
            # åˆ†ææƒ…ç»ª
            result = inference.analyze_emotion(text)
            
            print(f"   ğŸ“ˆ 27ç»´å‘é‡: [{result['emotion_vector'][0]:.3f}, {result['emotion_vector'][1]:.3f}, {result['emotion_vector'][2]:.3f}, ...]")
            print(f"   ğŸ¯ æœ€å¼ºæƒ…ç»ª: {result['max_emotion']} (å¼ºåº¦: {result['max_intensity']:.3f})")
            print(f"   ğŸ“Š æ€»ä½“æƒ…ç»ªå¼ºåº¦: {result['total_intensity']:.3f}")
            print(f"   ğŸ”¢ æ´»è·ƒæƒ…ç»ªæ•°é‡: {result['active_emotions']}")
            
            # æ˜¾ç¤ºå‰3ä¸ªæœ€å¼ºæƒ…ç»ª
            print("   ğŸ† å‰3ä¸ªæœ€å¼ºæƒ…ç»ª:")
            for emotion, intensity in result['top_emotions'][:3]:
                print(f"      {emotion}: {intensity:.3f}")
        
        print(f"\nâœ… æ¨¡å‹æµ‹è¯•å®Œæˆ!")
        print("ğŸ‰ ä½ çš„ACæ¨¡å—ç°åœ¨å¯ä»¥å°†æ–‡æœ¬è½¬æ¢ä¸º27ç»´æƒ…ç»ªå‘é‡äº†!")
        print("\nğŸ’¡ é›†æˆåˆ°ä½ çš„ç³»ç»Ÿä¸­:")
        print("   from test_simple_model import SimpleEmotionInference")
        print("   inference = SimpleEmotionInference()")
        print("   vector = inference.predict_emotion_vector('ä½ çš„æ–‡æœ¬')")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_trained_model()
    if not success:
        exit(1)