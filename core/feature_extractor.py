#!/usr/bin/env python3
"""
ç‰¹å¾æå–æ¨¡å— - 4.0ç‰ˆæœ¬æ ¸å¿ƒç»„ä»¶
è´Ÿè´£ä»è§†é¢‘ç‰‡æ®µä¸­æå–éŸ³ä¹ç‰¹å¾ï¼Œä¸ºæ£€ç´¢æä¾›åŸºç¡€
"""

import os
import json
import numpy as np
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import logging
import hashlib

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AudioFeatureExtractor:
    """
    éŸ³é¢‘ç‰¹å¾æå–å™¨
    ä»è§†é¢‘ä¸­æå–éŸ³é¢‘å¹¶åˆ†æå…¶éŸ³ä¹ç‰¹å¾
    """
    
    def __init__(self, features_dir: str = "materials/features"):
        """
        åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        
        Args:
            features_dir: ç‰¹å¾å­˜å‚¨ç›®å½•
        """
        self.features_dir = Path(features_dir)
        self.features_dir.mkdir(parents=True, exist_ok=True)
        
        # ç‰¹å¾ç¼“å­˜
        self.features_cache = {}
        self.load_features_cache()
    
    def extract_video_features(self, video_path: str, 
                             extract_ratio: float = 0.25) -> Optional[Dict[str, Any]]:
        """
        ä»è§†é¢‘ä¸­æå–éŸ³ä¹ç‰¹å¾
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            extract_ratio: æå–æ¯”ä¾‹ï¼ˆé»˜è®¤å‰25%ï¼Œå¯¹åº”ISOåŒ¹é…é˜¶æ®µï¼‰
            
        Returns:
            Dict: éŸ³ä¹ç‰¹å¾å­—å…¸
        """
        video_path = Path(video_path)
        
        if not video_path.exists():
            logger.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None
        
        # ç”Ÿæˆç‰¹å¾ID
        feature_id = self._generate_feature_id(video_path, extract_ratio)
        
        # æ£€æŸ¥ç¼“å­˜
        if feature_id in self.features_cache:
            logger.info(f"ä½¿ç”¨ç¼“å­˜ç‰¹å¾: {video_path.name}")
            return self.features_cache[feature_id]
        
        try:
            logger.info(f"æå–ç‰¹å¾: {video_path.name} (å‰{extract_ratio*100:.0f}%)")
            
            # 1. æå–éŸ³é¢‘
            audio_data = self._extract_audio_segment(video_path, extract_ratio)
            if audio_data is None:
                return None
            
            # 2. åˆ†æéŸ³é¢‘ç‰¹å¾
            features = self._analyze_audio_features(audio_data)
            if features is None:
                return None
            
            # 3. æ·»åŠ å…ƒæ•°æ®
            features.update({
                'video_path': str(video_path),
                'video_name': video_path.name,
                'extract_ratio': extract_ratio,
                'feature_id': feature_id,
                'extracted_at': datetime.now().isoformat(),
                'file_size': video_path.stat().st_size,
                'extractor_version': '4.0.0'
            })
            
            # 4. ä¿å­˜åˆ°ç¼“å­˜
            self.features_cache[feature_id] = features
            self._save_features_cache()
            
            logger.info(f"âœ… ç‰¹å¾æå–å®Œæˆ: {video_path.name}")
            return features
            
        except Exception as e:
            logger.error(f"ç‰¹å¾æå–å¤±è´¥: {video_path.name}, é”™è¯¯: {e}")
            return None
    
    def _generate_feature_id(self, video_path: Path, extract_ratio: float) -> str:
        """ç”Ÿæˆç‰¹å¾çš„å”¯ä¸€ID"""
        # åŸºäºæ–‡ä»¶è·¯å¾„ã€å¤§å°ã€ä¿®æ”¹æ—¶é—´å’Œæå–æ¯”ä¾‹ç”Ÿæˆå“ˆå¸Œ
        stat = video_path.stat()
        content = f"{video_path.name}_{stat.st_size}_{stat.st_mtime}_{extract_ratio}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _extract_audio_segment(self, video_path: Path, extract_ratio: float) -> Optional[np.ndarray]:
        """
        ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            extract_ratio: æå–æ¯”ä¾‹
            
        Returns:
            np.ndarray: éŸ³é¢‘æ•°æ®
        """
        try:
            # é¦–å…ˆè·å–è§†é¢‘æ—¶é•¿
            duration = self._get_video_duration(video_path)
            if duration is None:
                return None
            
            # è®¡ç®—æå–æ—¶é•¿
            extract_duration = duration * extract_ratio
            
            # åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
                temp_audio_path = temp_audio.name
            
            try:
                # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
                cmd = [
                    'ffmpeg', '-y',
                    '-i', str(video_path),
                    '-t', str(extract_duration),  # åªæå–å‰Nç§’
                    '-vn',  # ä¸è¦è§†é¢‘
                    '-acodec', 'pcm_s16le',  # 16ä½PCM
                    '-ar', '22050',  # 22.05kHzé‡‡æ ·ç‡
                    '-ac', '1',  # å•å£°é“
                    temp_audio_path
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                
                if result.returncode != 0:
                    logger.error(f"ffmpegéŸ³é¢‘æå–å¤±è´¥: {result.stderr}")
                    return None
                
                # è¯»å–éŸ³é¢‘æ•°æ®
                audio_data = self._load_audio_file(temp_audio_path)
                return audio_data
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_audio_path):
                    os.unlink(temp_audio_path)
                    
        except Exception as e:
            logger.error(f"éŸ³é¢‘æå–å¤±è´¥: {e}")
            return None
    
    def _get_video_duration(self, video_path: Path) -> Optional[float]:
        """è·å–è§†é¢‘æ—¶é•¿"""
        try:
            cmd = [
                'ffprobe', '-v', 'quiet', '-print_format', 'json',
                '-show_format', str(video_path)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode != 0:
                return None
            
            data = json.loads(result.stdout)
            return float(data['format'].get('duration', 0))
            
        except Exception:
            return None
    
    def _load_audio_file(self, audio_path: str) -> Optional[np.ndarray]:
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶ä¸ºnumpyæ•°ç»„"""
        try:
            # å°è¯•ä½¿ç”¨librosaï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                import librosa
                audio_data, sr = librosa.load(audio_path, sr=22050, mono=True)
                return audio_data
            except ImportError:
                pass
            
            # å¦‚æœæ²¡æœ‰librosaï¼Œä½¿ç”¨scipy
            try:
                from scipy.io import wavfile
                sr, audio_data = wavfile.read(audio_path)
                
                # è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–
                if audio_data.dtype == np.int16:
                    audio_data = audio_data.astype(np.float32) / 32768.0
                elif audio_data.dtype == np.int32:
                    audio_data = audio_data.astype(np.float32) / 2147483648.0
                
                return audio_data
            except ImportError:
                pass
            
            # æœ€åå°è¯•ä½¿ç”¨ffmpegè¯»å–
            return self._load_audio_with_ffmpeg(audio_path)
            
        except Exception as e:
            logger.error(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _load_audio_with_ffmpeg(self, audio_path: str) -> Optional[np.ndarray]:
        """ä½¿ç”¨ffmpegè¯»å–éŸ³é¢‘æ•°æ®"""
        try:
            cmd = [
                'ffmpeg', '-i', audio_path, '-f', 'f32le', '-acodec', 'pcm_f32le', '-'
            ]
            
            result = subprocess.run(cmd, capture_output=True, timeout=30)
            
            if result.returncode != 0:
                return None
            
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºfloat32æ•°ç»„
            audio_data = np.frombuffer(result.stdout, dtype=np.float32)
            return audio_data
            
        except Exception:
            return None
    
    def _analyze_audio_features(self, audio_data: np.ndarray, sr: int = 22050) -> Optional[Dict[str, Any]]:
        """
        åˆ†æéŸ³é¢‘ç‰¹å¾
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sr: é‡‡æ ·ç‡
            
        Returns:
            Dict: éŸ³é¢‘ç‰¹å¾
        """
        try:
            features = {}
            
            # 1. åŸºç¡€ç»Ÿè®¡ç‰¹å¾
            features.update(self._extract_basic_features(audio_data))
            
            # 2. é¢‘åŸŸç‰¹å¾
            features.update(self._extract_frequency_features(audio_data, sr))
            
            # 3. æ—¶åŸŸç‰¹å¾
            features.update(self._extract_temporal_features(audio_data, sr))
            
            # 4. æ„ŸçŸ¥ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
            features.update(self._extract_perceptual_features(audio_data, sr))
            
            return features
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘ç‰¹å¾åˆ†æå¤±è´¥: {e}")
            return None
    
    def _extract_basic_features(self, audio_data: np.ndarray) -> Dict[str, float]:
        """æå–åŸºç¡€ç»Ÿè®¡ç‰¹å¾"""
        return {
            'duration': len(audio_data) / 22050,  # æ—¶é•¿ï¼ˆç§’ï¼‰
            'rms_energy': float(np.sqrt(np.mean(audio_data**2))),  # RMSèƒ½é‡
            'zero_crossing_rate': float(np.mean(np.abs(np.diff(np.sign(audio_data))) / 2)),  # è¿‡é›¶ç‡
            'amplitude_mean': float(np.mean(np.abs(audio_data))),  # å¹³å‡æŒ¯å¹…
            'amplitude_std': float(np.std(audio_data)),  # æŒ¯å¹…æ ‡å‡†å·®
            'amplitude_max': float(np.max(np.abs(audio_data))),  # æœ€å¤§æŒ¯å¹…
            'dynamic_range': float(np.max(audio_data) - np.min(audio_data))  # åŠ¨æ€èŒƒå›´
        }
    
    def _extract_frequency_features(self, audio_data: np.ndarray, sr: int) -> Dict[str, float]:
        """æå–é¢‘åŸŸç‰¹å¾"""
        # è®¡ç®—FFT
        fft = np.fft.fft(audio_data)
        magnitude = np.abs(fft[:len(fft)//2])
        
        # é¢‘ç‡è½´
        freqs = np.fft.fftfreq(len(audio_data), 1/sr)[:len(fft)//2]
        
        # å½’ä¸€åŒ–
        if np.sum(magnitude) > 0:
            magnitude = magnitude / np.sum(magnitude)
        
        # ç‰¹å¾æå–
        features = {}
        
        # è´¨å¿ƒé¢‘ç‡
        if np.sum(magnitude) > 0:
            features['spectral_centroid'] = float(np.sum(freqs * magnitude) / np.sum(magnitude))
        else:
            features['spectral_centroid'] = 0.0
        
        # é¢‘è°±å¸¦å®½
        if features['spectral_centroid'] > 0:
            features['spectral_bandwidth'] = float(
                np.sqrt(np.sum(((freqs - features['spectral_centroid']) ** 2) * magnitude) / np.sum(magnitude))
            )
        else:
            features['spectral_bandwidth'] = 0.0
        
        # é¢‘è°±æ»šé™ç‚¹
        cumsum = np.cumsum(magnitude)
        if cumsum[-1] > 0:
            rolloff_idx = np.where(cumsum >= 0.85 * cumsum[-1])[0]
            features['spectral_rolloff'] = float(freqs[rolloff_idx[0]] if len(rolloff_idx) > 0 else 0)
        else:
            features['spectral_rolloff'] = 0.0
        
        # é¢‘è°±å¹³å¦åº¦
        if np.mean(magnitude) > 0:
            geometric_mean = np.exp(np.mean(np.log(magnitude + 1e-10)))
            arithmetic_mean = np.mean(magnitude)
            features['spectral_flatness'] = float(geometric_mean / arithmetic_mean)
        else:
            features['spectral_flatness'] = 0.0
        
        return features
    
    def _extract_temporal_features(self, audio_data: np.ndarray, sr: int) -> Dict[str, float]:
        """æå–æ—¶åŸŸç‰¹å¾"""
        features = {}
        
        # åˆ†å¸§åˆ†æ
        frame_length = int(0.025 * sr)  # 25mså¸§
        hop_length = int(0.01 * sr)     # 10msè·³è·ƒ
        
        frames = []
        for i in range(0, len(audio_data) - frame_length, hop_length):
            frames.append(audio_data[i:i + frame_length])
        
        if not frames:
            return {
                'tempo_estimate': 0.0,
                'rhythm_regularity': 0.0,
                'onset_density': 0.0
            }
        
        # ç®€åŒ–çš„èŠ‚æ‹ä¼°è®¡
        frame_energies = [np.sum(frame**2) for frame in frames]
        energy_diffs = np.abs(np.diff(frame_energies))
        
        # å¯»æ‰¾èƒ½é‡å³°å€¼ï¼ˆç®€å•çš„onsetæ£€æµ‹ï¼‰
        threshold = np.mean(energy_diffs) + np.std(energy_diffs)
        onsets = np.where(energy_diffs > threshold)[0]
        
        # ä¼°è®¡tempo
        if len(onsets) > 1:
            onset_intervals = np.diff(onsets) * hop_length / sr
            if len(onset_intervals) > 0:
                avg_interval = np.median(onset_intervals)
                tempo_estimate = 60.0 / avg_interval if avg_interval > 0 else 0
                features['tempo_estimate'] = float(min(tempo_estimate, 200))  # é™åˆ¶åœ¨åˆç†èŒƒå›´
            else:
                features['tempo_estimate'] = 0.0
            
            # èŠ‚å¥è§„å¾‹æ€§
            if len(onset_intervals) > 0:
                features['rhythm_regularity'] = float(1.0 / (1.0 + np.std(onset_intervals)))
            else:
                features['rhythm_regularity'] = 0.0
        else:
            features['tempo_estimate'] = 0.0
            features['rhythm_regularity'] = 0.0
        
        # Onsetå¯†åº¦
        features['onset_density'] = float(len(onsets) / (len(audio_data) / sr))
        
        return features
    
    def _extract_perceptual_features(self, audio_data: np.ndarray, sr: int) -> Dict[str, float]:
        """æå–æ„ŸçŸ¥ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        features = {}
        
        # å“åº¦ä¼°è®¡ï¼ˆåŸºäºRMSï¼‰
        rms = np.sqrt(np.mean(audio_data**2))
        features['loudness_estimate'] = float(20 * np.log10(rms + 1e-10))  # dB
        
        # äº®åº¦ä¼°è®¡ï¼ˆé«˜é¢‘èƒ½é‡æ¯”ä¾‹ï¼‰
        fft = np.abs(np.fft.fft(audio_data))
        total_energy = np.sum(fft**2)
        
        if total_energy > 0:
            # é«˜é¢‘ï¼ˆ>1kHzï¼‰èƒ½é‡æ¯”ä¾‹
            high_freq_start = int(1000 * len(fft) / sr)
            high_freq_energy = np.sum(fft[high_freq_start:]**2)
            features['brightness'] = float(high_freq_energy / total_energy)
        else:
            features['brightness'] = 0.0
        
        # æ¸©æš–åº¦ä¼°è®¡ï¼ˆä½é¢‘èƒ½é‡æ¯”ä¾‹ï¼‰
        if total_energy > 0:
            # ä½é¢‘ï¼ˆ<500Hzï¼‰èƒ½é‡æ¯”ä¾‹
            low_freq_end = int(500 * len(fft) / sr)
            low_freq_energy = np.sum(fft[:low_freq_end]**2)
            features['warmth'] = float(low_freq_energy / total_energy)
        else:
            features['warmth'] = 0.0
        
        # ç²—ç³™åº¦ä¼°è®¡ï¼ˆåŸºäºé¢‘è°±ä¸è§„åˆ™æ€§ï¼‰
        if len(fft) > 2:
            spectral_diff = np.diff(fft[:len(fft)//2])
            features['roughness'] = float(np.std(spectral_diff))
        else:
            features['roughness'] = 0.0
        
        return features
    
    def extract_batch_features(self, video_list: List[Dict[str, Any]], 
                             extract_ratio: float = 0.25) -> Dict[str, Dict[str, Any]]:
        """
        æ‰¹é‡æå–ç‰¹å¾
        
        Args:
            video_list: è§†é¢‘ä¿¡æ¯åˆ—è¡¨
            extract_ratio: æå–æ¯”ä¾‹
            
        Returns:
            Dict: è§†é¢‘è·¯å¾„åˆ°ç‰¹å¾çš„æ˜ å°„
        """
        features_db = {}
        
        logger.info(f"å¼€å§‹æ‰¹é‡ç‰¹å¾æå–ï¼Œå…± {len(video_list)} ä¸ªè§†é¢‘")
        
        for i, video_info in enumerate(video_list, 1):
            video_path = video_info.get('segment_path') or video_info.get('file_path')
            
            if not video_path:
                logger.warning(f"è§†é¢‘ä¿¡æ¯ç¼ºå°‘è·¯å¾„: {video_info}")
                continue
            
            logger.info(f"å¤„ç† {i}/{len(video_list)}: {Path(video_path).name}")
            
            features = self.extract_video_features(video_path, extract_ratio)
            
            if features:
                features_db[video_path] = features
                # æ·»åŠ è§†é¢‘ä¿¡æ¯
                features.update({
                    'source_info': video_info
                })
            else:
                logger.warning(f"ç‰¹å¾æå–å¤±è´¥: {video_path}")
        
        logger.info(f"âœ… æ‰¹é‡ç‰¹å¾æå–å®Œæˆï¼ŒæˆåŠŸ {len(features_db)}/{len(video_list)}")
        
        # ä¿å­˜ç‰¹å¾æ•°æ®åº“
        self._save_features_database(features_db)
        
        return features_db
    
    def _save_features_database(self, features_db: Dict[str, Dict[str, Any]]):
        """ä¿å­˜ç‰¹å¾æ•°æ®åº“"""
        db_file = self.features_dir / "features_database.json"
        
        try:
            with open(db_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'features_database': features_db,
                    'created_at': datetime.now().isoformat(),
                    'total_videos': len(features_db),
                    'extractor_version': '4.0.0'
                }, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… ç‰¹å¾æ•°æ®åº“å·²ä¿å­˜: {db_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç‰¹å¾æ•°æ®åº“å¤±è´¥: {e}")
    
    def load_features_database(self) -> Optional[Dict[str, Dict[str, Any]]]:
        """åŠ è½½ç‰¹å¾æ•°æ®åº“"""
        db_file = self.features_dir / "features_database.json"
        
        if not db_file.exists():
            logger.info("ç‰¹å¾æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
            return None
        
        try:
            with open(db_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            features_db = data.get('features_database', {})
            logger.info(f"âœ… åŠ è½½ç‰¹å¾æ•°æ®åº“æˆåŠŸï¼Œå…± {len(features_db)} ä¸ªè§†é¢‘ç‰¹å¾")
            
            return features_db
            
        except Exception as e:
            logger.error(f"åŠ è½½ç‰¹å¾æ•°æ®åº“å¤±è´¥: {e}")
            return None
    
    def _save_features_cache(self):
        """ä¿å­˜ç‰¹å¾ç¼“å­˜"""
        cache_file = self.features_dir / "features_cache.json"
        
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.features_cache, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜ç‰¹å¾ç¼“å­˜å¤±è´¥: {e}")
    
    def load_features_cache(self):
        """åŠ è½½ç‰¹å¾ç¼“å­˜"""
        cache_file = self.features_dir / "features_cache.json"
        
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.features_cache = json.load(f)
                logger.info(f"åŠ è½½ç‰¹å¾ç¼“å­˜: {len(self.features_cache)} é¡¹")
            except Exception as e:
                logger.error(f"åŠ è½½ç‰¹å¾ç¼“å­˜å¤±è´¥: {e}")
                self.features_cache = {}
        else:
            self.features_cache = {}

if __name__ == "__main__":
    # æµ‹è¯•ç‰¹å¾æå–å™¨
    extractor = AudioFeatureExtractor()
    
    # æµ‹è¯•å•ä¸ªè§†é¢‘
    test_video = "materials/video/32.mp4"
    
    if os.path.exists(test_video):
        print(f"ğŸµ æµ‹è¯•ç‰¹å¾æå–: {test_video}")
        features = extractor.extract_video_features(test_video)
        
        if features:
            print("âœ… ç‰¹å¾æå–æˆåŠŸ!")
            print(f"   æ—¶é•¿: {features.get('duration', 0):.1f}ç§’")
            print(f"   RMSèƒ½é‡: {features.get('rms_energy', 0):.4f}")
            print(f"   é¢‘è°±è´¨å¿ƒ: {features.get('spectral_centroid', 0):.1f}Hz")
            print(f"   ä¼°è®¡èŠ‚æ‹: {features.get('tempo_estimate', 0):.1f}BPM")
            print(f"   äº®åº¦: {features.get('brightness', 0):.3f}")
            print(f"   æ¸©æš–åº¦: {features.get('warmth', 0):.3f}")
        else:
            print("âŒ ç‰¹å¾æå–å¤±è´¥")
    else:
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {test_video}")