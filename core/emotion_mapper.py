#!/usr/bin/env python3
"""
æƒ…ç»ªè¯†åˆ«ä¸æ˜ å°„æ¨¡å— - ä»qm_final3è¿ç§»å¹¶ä¼˜åŒ–
ç”¨äº4.0ç‰ˆæœ¬çš„æ£€ç´¢é€»è¾‘
"""

import re
from typing import Dict, Tuple, List, Any
from datetime import datetime

class EmotionRecognizer:
    """
    27ç»´æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ
    åŸºäºå…³é”®è¯åŒ¹é…å’Œè¯­ä¹‰åˆ†æçš„æƒ…ç»ªæ£€æµ‹
    """
    
    def __init__(self):
        # åŸºç¡€5ç»´æƒ…ç»ªï¼ˆä¿æŒä¸3.0ç‰ˆæœ¬å…¼å®¹ï¼‰
        self.base_emotions = {
            "ç„¦è™‘": ["ç„¦è™‘", "ç´§å¼ ", "æ‹…å¿ƒ", "ä¸å®‰", "å®³æ€•", "ææƒ§", "å¿ƒè·³", "å¿å¿‘", "æƒ¶æ"],
            "ç–²æƒ«": ["ç–²æƒ«", "ç´¯", "ç–²åŠ³", "å›°å€¦", "ä¹åŠ›", "æ— åŠ›", "ç–²å€¦", "å›°", "ç²¾ç–²åŠ›ç«­"],
            "çƒ¦èº": ["çƒ¦èº", "çƒ¦æ¼", "æ˜“æ€’", "æ€¥èº", "ä¸è€çƒ¦", "æš´èº", "æ„¤æ€’", "ç”Ÿæ°”", "æ¼ç«"],
            "å¹³é™": ["å¹³é™", "æ”¾æ¾", "å®‰é™", "å®é™", "èˆ’ç¼“", "è½»æ¾", "å®‰é€¸", "ç¥¥å’Œ", "æ·¡å®š"],
            "å‹åŠ›": ["å‹åŠ›", "ç´§è¿«", "è´Ÿæ‹…", "é‡å‹", "æ²‰é‡", "å‹æŠ‘", "ç´§å¼ ", "è´Ÿé‡", "å–˜ä¸è¿‡æ°”"]
        }
        
        # æ‰©å±•ç¡çœ ä¸“ç”¨æƒ…ç»ªç»´åº¦ï¼ˆé€‚é…27ç»´ç³»ç»Ÿï¼‰
        self.sleep_specific_emotions = {
            "ååˆæ€è€ƒ": ["ååˆ", "èƒ¡æ€ä¹±æƒ³", "æƒ³å¤ªå¤š", "æ€ç»´å¾ªç¯", "é’»ç‰›è§’å°–"],
            "ç¡çœ ç„¦è™‘": ["ç¡ä¸ç€", "å¤±çœ ", "ç¡çœ ç„¦è™‘", "æ€•ç¡ä¸å¥½", "æ‹…å¿ƒç¡çœ "],
            "èº«ä½“ç–²æƒ«": ["èº«ä½“ç´¯", "è‚Œè‚‰é…¸ç—›", "ä½“åŠ›ä¸æ”¯", "èº«ä½“æ²‰é‡"],
            "ç²¾ç¥ç–²æƒ«": ["è„‘å­ç´¯", "ç²¾ç¥ç–²åŠ³", "å¿ƒç´¯", "æ€ç»´ç–²æƒ«"],
            "è¿‡åº¦è§‰é†’": ["å¤ªå…´å¥‹", "ç¡ä¸ä¸‹", "ç²¾ç¥äº¢å¥‹", "å¤§è„‘æ´»è·ƒ"],
            "å°±å¯æ‹…å¿§": ["ç¡å‰æ‹…å¿ƒ", "æ˜å¤©çš„äº‹", "å·¥ä½œå‹åŠ›", "ç”Ÿæ´»çƒ¦æ¼"],
            "æ€ç»´å¥”é€¸": ["åœä¸ä¸‹æ¥", "æ€ç»ªé£è½¬", "è„‘å­è½¬ä¸ªä¸åœ", "æƒ³æ³•å¾ˆå¤š"],
            "èº¯ä½“ç´§å¼ ": ["è‚Œè‚‰ç´§å¼ ", "èº«ä½“åƒµç¡¬", "æ— æ³•æ”¾æ¾", "ç»·å¾—å¾ˆç´§"]
        }
        
        # åˆå¹¶æ‰€æœ‰æƒ…ç»ªç±»åˆ«
        self.all_emotions = {**self.base_emotions, **self.sleep_specific_emotions}
        
    def detect_emotion(self, user_input: str) -> Tuple[str, float]:
        """
        å¢å¼ºæƒ…ç»ªæ£€æµ‹
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„æƒ…ç»ªæè¿°
            
        Returns:
            Tuple[str, float]: (æ£€æµ‹åˆ°çš„æƒ…ç»ª, ç½®ä¿¡åº¦)
        """
        if not user_input or len(user_input.strip()) < 2:
            return "ç„¦è™‘", 0.85
        
        # æ¸…ç†è¾“å…¥
        cleaned_input = self._clean_input(user_input)
        
        # è®¡ç®—æƒ…ç»ªå¾—åˆ†
        emotion_scores = {}
        for emotion, keywords in self.all_emotions.items():
            score = self._calculate_emotion_score(cleaned_input, keywords)
            if score > 0:
                emotion_scores[emotion] = score
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä¸“ç”¨æƒ…ç»ªï¼Œä½¿ç”¨åŸºç¡€æƒ…ç»ª
        if not emotion_scores:
            for emotion, keywords in self.base_emotions.items():
                score = self._calculate_emotion_score(cleaned_input, keywords)
                if score > 0:
                    emotion_scores[emotion] = score
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æƒ…ç»ª
        if emotion_scores:
            detected_emotion = max(emotion_scores.items(), key=lambda x: x[1])
            emotion_name = detected_emotion[0]
            base_confidence = 0.85 + detected_emotion[1] * 0.03
            confidence = min(base_confidence, 0.95)
        else:
            # é»˜è®¤æƒ…ç»ª
            emotion_name = "ç„¦è™‘"
            confidence = 0.80
        
        return emotion_name, confidence
    
    def _clean_input(self, text: str) -> str:
        """æ¸…ç†è¾“å…¥æ–‡æœ¬"""
        # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹
        cleaned = re.sub(r'[^\w\s]', '', text)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        return cleaned.lower()
    
    def _calculate_emotion_score(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—æƒ…ç»ªå…³é”®è¯åŒ¹é…å¾—åˆ†"""
        score = 0
        for keyword in keywords:
            if keyword in text:
                # å®Œå…¨åŒ¹é…å¾—2åˆ†ï¼Œéƒ¨åˆ†åŒ¹é…å¾—1åˆ†
                if keyword == text or f" {keyword} " in f" {text} ":
                    score += 2
                else:
                    score += 1
        return score
    
    def get_emotion_details(self, emotion: str) -> Dict[str, Any]:
        """è·å–æƒ…ç»ªçš„è¯¦ç»†ä¿¡æ¯"""
        # åˆ¤æ–­æ˜¯åŸºç¡€æƒ…ç»ªè¿˜æ˜¯ç¡çœ ä¸“ç”¨æƒ…ç»ª
        if emotion in self.base_emotions:
            category = "åŸºç¡€æƒ…ç»ª"
            keywords = self.base_emotions[emotion]
        elif emotion in self.sleep_specific_emotions:
            category = "ç¡çœ ä¸“ç”¨æƒ…ç»ª"
            keywords = self.sleep_specific_emotions[emotion]
        else:
            category = "æœªçŸ¥"
            keywords = []
        
        return {
            "emotion": emotion,
            "category": category,
            "keywords": keywords,
            "dimension_count": len(self.all_emotions),
            "timestamp": datetime.now().isoformat()
        }

class MusicFeatureMapper:
    """
    æƒ…ç»ªåˆ°éŸ³ä¹ç‰¹å¾çš„æ˜ å°„ç³»ç»Ÿ
    åŸºäºISOä¸‰é˜¶æ®µåŸåˆ™å’ŒéŸ³ä¹ç–—æ„ˆç†è®º
    """
    
    def __init__(self):
        # ISOä¸‰é˜¶æ®µéŸ³ä¹ç‰¹å¾æ•°æ®åº“ï¼ˆä»3.0ç‰ˆæœ¬è¿ç§»ï¼‰
        self.features_database = {
            "ç„¦è™‘": {
                "åŒ¹é…é˜¶æ®µ": {
                    "tempo": "moderate tense",
                    "key": "minor anxious", 
                    "dynamics": "restless energy",
                    "mood": "matching anxiety",
                    "instrumental": "strings, piano",
                    "texture": "complex, layered"
                },
                "å¼•å¯¼é˜¶æ®µ": {
                    "tempo": "gradually calming",
                    "key": "minor to neutral transition",
                    "dynamics": "settling down", 
                    "mood": "guiding to peace",
                    "instrumental": "soft piano, ambient",
                    "texture": "simplifying"
                },
                "ç›®æ ‡é˜¶æ®µ": {
                    "tempo": "slow peaceful",
                    "key": "major calm",
                    "dynamics": "gentle soft",
                    "mood": "deep relaxation for sleep",
                    "instrumental": "ambient pads, nature",
                    "texture": "minimal, spacious"
                }
            },
            "ç–²æƒ«": {
                "åŒ¹é…é˜¶æ®µ": {
                    "tempo": "tired sluggish",
                    "key": "minor weary",
                    "dynamics": "heavy fatigue",
                    "mood": "exhausted state",
                    "instrumental": "cello, low piano",
                    "texture": "heavy, dragging"
                },
                "å¼•å¯¼é˜¶æ®µ": {
                    "tempo": "gentle restoration",
                    "key": "minor to warm transition", 
                    "dynamics": "nurturing support",
                    "mood": "healing tiredness",
                    "instrumental": "warm strings, harp",
                    "texture": "supportive, embracing"
                },
                "ç›®æ ‡é˜¶æ®µ": {
                    "tempo": "deeply restful",
                    "key": "warm major",
                    "dynamics": "embracing comfort",
                    "mood": "restorative sleep",
                    "instrumental": "soft choir, ambient",
                    "texture": "enveloping, safe"
                }
            },
            "çƒ¦èº": {
                "åŒ¹é…é˜¶æ®µ": {
                    "tempo": "agitated irregular",
                    "key": "dissonant minor",
                    "dynamics": "sharp edges",
                    "mood": "irritated energy",
                    "instrumental": "staccato strings, percussion",
                    "texture": "angular, restless"
                },
                "å¼•å¯¼é˜¶æ®µ": {
                    "tempo": "smoothing out",
                    "key": "resolving tensions",
                    "dynamics": "softening edges",
                    "mood": "releasing irritation",
                    "instrumental": "flowing strings, woodwinds",
                    "texture": "smoothing, flowing"
                },
                "ç›®æ ‡é˜¶æ®µ": {
                    "tempo": "smooth flowing",
                    "key": "resolved major",
                    "dynamics": "peaceful waves",
                    "mood": "serene sleep state",
                    "instrumental": "soft pads, gentle waves",
                    "texture": "fluid, peaceful"
                }
            },
            "å¹³é™": {
                "åŒ¹é…é˜¶æ®µ": {
                    "tempo": "naturally calm",
                    "key": "neutral peaceful",
                    "dynamics": "already gentle",
                    "mood": "existing tranquility",
                    "instrumental": "soft piano, strings",
                    "texture": "balanced, serene"
                },
                "å¼•å¯¼é˜¶æ®µ": {
                    "tempo": "deepening calm",
                    "key": "enriching peace",
                    "dynamics": "expanding serenity",
                    "mood": "enhancing stillness",
                    "instrumental": "ambient, soft choir",
                    "texture": "expanding, deepening"
                },
                "ç›®æ ‡é˜¶æ®µ": {
                    "tempo": "profound stillness",
                    "key": "deep major",
                    "dynamics": "whisper soft",
                    "mood": "transcendent sleep",
                    "instrumental": "pure tones, silence",
                    "texture": "minimal, transcendent"
                }
            },
            "å‹åŠ›": {
                "åŒ¹é…é˜¶æ®µ": {
                    "tempo": "pressured urgent",
                    "key": "tense minor",
                    "dynamics": "compressed energy",
                    "mood": "stress overload",
                    "instrumental": "tight strings, muted brass",
                    "texture": "compressed, intense"
                },
                "å¼•å¯¼é˜¶æ®µ": {
                    "tempo": "releasing pressure",
                    "key": "opening up space",
                    "dynamics": "expanding freedom",
                    "mood": "letting go stress",
                    "instrumental": "opening brass, flowing strings",
                    "texture": "expanding, liberating"
                },
                "ç›®æ ‡é˜¶æ®µ": {
                    "tempo": "weightless floating",
                    "key": "liberated major",
                    "dynamics": "free flowing",
                    "mood": "stress-free sleep",
                    "instrumental": "ambient space, soft pads",
                    "texture": "weightless, free"
                }
            }
        }
        
        # ä¸ºç¡çœ ä¸“ç”¨æƒ…ç»ªåˆ›å»ºé»˜è®¤æ˜ å°„
        self._create_sleep_emotion_mappings()
    
    def _create_sleep_emotion_mappings(self):
        """ä¸ºç¡çœ ä¸“ç”¨æƒ…ç»ªåˆ›å»ºéŸ³ä¹ç‰¹å¾æ˜ å°„"""
        sleep_emotions = [
            "ååˆæ€è€ƒ", "ç¡çœ ç„¦è™‘", "èº«ä½“ç–²æƒ«", "ç²¾ç¥ç–²æƒ«", 
            "è¿‡åº¦è§‰é†’", "å°±å¯æ‹…å¿§", "æ€ç»´å¥”é€¸", "èº¯ä½“ç´§å¼ "
        ]
        
        for emotion in sleep_emotions:
            if emotion not in self.features_database:
                # æ ¹æ®ç¡çœ æƒ…ç»ªç‰¹ç‚¹åˆ†é…åŸºç¡€æ¨¡æ¿
                if "ç„¦è™‘" in emotion or "æ‹…å¿§" in emotion:
                    template = self.features_database["ç„¦è™‘"]
                elif "ç–²æƒ«" in emotion:
                    template = self.features_database["ç–²æƒ«"]
                elif "è§‰é†’" in emotion or "å¥”é€¸" in emotion:
                    template = self.features_database["çƒ¦èº"]
                elif "ç´§å¼ " in emotion:
                    template = self.features_database["å‹åŠ›"]
                else:
                    template = self.features_database["ç„¦è™‘"]  # é»˜è®¤
                
                # å¤åˆ¶æ¨¡æ¿å¹¶åšå°çš„è°ƒæ•´
                self.features_database[emotion] = {
                    stage: {**features, "mood": f"{emotion} - {features['mood']}"}
                    for stage, features in template.items()
                }
    
    def get_music_features(self, emotion: str) -> Dict[str, Any]:
        """
        æ ¹æ®æƒ…ç»ªè·å–ISOä¸‰é˜¶æ®µéŸ³ä¹ç‰¹å¾
        
        Args:
            emotion: æ£€æµ‹åˆ°çš„æƒ…ç»ª
            
        Returns:
            Dict: åŒ…å«ä¸‰é˜¶æ®µéŸ³ä¹ç‰¹å¾çš„å­—å…¸
        """
        if emotion in self.features_database:
            return self.features_database[emotion]
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ç„¦è™‘ä½œä¸ºé»˜è®¤
            print(f"âš ï¸ æœªæ‰¾åˆ°æƒ…ç»ª '{emotion}' çš„éŸ³ä¹ç‰¹å¾ï¼Œä½¿ç”¨é»˜è®¤(ç„¦è™‘)")
            return self.features_database["ç„¦è™‘"]
    
    def extract_matching_stage_features(self, emotion: str) -> Dict[str, Any]:
        """
        æå–åŒ¹é…é˜¶æ®µçš„ç‰¹å¾ï¼ˆç”¨äºæ£€ç´¢ï¼‰
        è¿™å¯¹åº”å‰25%çš„è§†é¢‘å†…å®¹ç‰¹å¾
        
        Args:
            emotion: æƒ…ç»ªç±»å‹
            
        Returns:
            Dict: åŒ¹é…é˜¶æ®µçš„éŸ³ä¹ç‰¹å¾
        """
        features = self.get_music_features(emotion)
        matching_features = features["åŒ¹é…é˜¶æ®µ"]
        
        # æ·»åŠ æ£€ç´¢ç›¸å…³çš„å…ƒæ•°æ®
        matching_features["emotion"] = emotion
        matching_features["stage"] = "åŒ¹é…é˜¶æ®µ"
        matching_features["iso_stage_ratio"] = 0.25  # å‰25%
        
        return matching_features
    
    def get_supported_emotions(self) -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æƒ…ç»ªç±»å‹"""
        return list(self.features_database.keys())

# å•ä¾‹å®ä¾‹ï¼Œä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
emotion_recognizer = EmotionRecognizer()
music_feature_mapper = MusicFeatureMapper()

def detect_emotion_enhanced(user_input: str) -> Tuple[str, float]:
    """
    å¢å¼ºæƒ…ç»ªæ£€æµ‹çš„ä¾¿æ·å‡½æ•°
    ä¿æŒä¸3.0ç‰ˆæœ¬çš„APIå…¼å®¹æ€§
    """
    return emotion_recognizer.detect_emotion(user_input)

def get_emotion_music_features(emotion: str) -> Dict[str, Any]:
    """
    è·å–æƒ…ç»ªéŸ³ä¹ç‰¹å¾çš„ä¾¿æ·å‡½æ•°
    ä¿æŒä¸3.0ç‰ˆæœ¬çš„APIå…¼å®¹æ€§
    """
    return music_feature_mapper.get_music_features(emotion)

if __name__ == "__main__":
    # æµ‹è¯•æƒ…ç»ªè¯†åˆ«
    test_inputs = [
        "æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œéš¾ä»¥å…¥ç¡",
        "å¤ªç´¯äº†ï¼Œèº«ä½“å’Œç²¾ç¥éƒ½å¾ˆç–²æƒ«",
        "ä»Šæ™šåˆå¼€å§‹èƒ¡æ€ä¹±æƒ³ï¼Œåœä¸ä¸‹æ¥",
        "å‹åŠ›å¾ˆå¤§ï¼Œæ„Ÿè§‰å–˜ä¸è¿‡æ°”",
        "æ¯”è¾ƒå¹³é™ï¼Œä½†å¸Œæœ›æ›´æ·±å±‚çš„æ”¾æ¾"
    ]
    
    print("ğŸ§  æƒ…ç»ªè¯†åˆ«æµ‹è¯•ï¼š")
    for text in test_inputs:
        emotion, confidence = detect_emotion_enhanced(text)
        print(f"è¾“å…¥: {text}")
        print(f"è¯†åˆ«: {emotion} (ç½®ä¿¡åº¦: {confidence:.2%})")
        
        features = get_emotion_music_features(emotion)
        matching = features["åŒ¹é…é˜¶æ®µ"]
        print(f"åŒ¹é…é˜¶æ®µç‰¹å¾: {matching['mood']}, {matching['tempo']}")
        print("-" * 50)